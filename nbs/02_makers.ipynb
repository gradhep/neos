{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp makers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neos.makers\n",
    "\n",
    "> Functions that define the workflow from parametric observable --> statistical model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module contains example workflows to go from the output of a neural network to a differentiable histogram, and to then use that as a basis for statistical modelling via the [HistFactory likelihood specification](https://scikit-hep.org/pyhf/intro.html#histfactory).\n",
    "\n",
    "These functions are designed to be composed such that a final metric (e.g. expected p-value) is explicitly made a function of the parameters of the neural network. You can see this behaviour through the nested function design; one can specify all other hyperparameters ahead of time when initializing the functions, and the nn weights don't have to be specified until the inner function is called. Keep reading for examples!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## differentiable histograms from neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from functools import partial\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "from relaxed import hist_kde as hist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def hists_from_nn(\n",
    "    data_generator, predict, hpar_dict, method=\"softmax\", LUMI=10, sig_scale=2, bkg_scale=10, \n",
    "):\n",
    "    \"\"\"Initialize a function `hist_maker` that returns a 'soft' histogram based\n",
    "    on a neural network with a softmax output. Choose which example problem to\n",
    "    try by setting the `example` argument.\n",
    "\n",
    "    Args:\n",
    "        data_generator: Callable that returns generated data (in jax array \n",
    "                        format).\n",
    "\n",
    "        predict: Decision function for a parameterized observable, e.g. neural \n",
    "                 network.\n",
    "\n",
    "        method: A string to specify the method to use for constructing soft \n",
    "                histograms. Either \"softmax\" or \"kde\".\n",
    "\n",
    "        LUMI: 'Luminosity' scaling factor for the yields.\n",
    "\n",
    "        sig_scale: Individual scaling factor for the signal yields.\n",
    "\n",
    "        bkg_scale: Individual scaling factor for the signal yields.\n",
    "\n",
    "    Returns:\n",
    "        hist_maker: A callable function that takes the parameters of the \n",
    "                    observable (and optional hyperpars), then constructs signal,\n",
    "                    background, and background uncertainty yields.\n",
    "    \"\"\"\n",
    "\n",
    "    data = data_generator()\n",
    "\n",
    "    if len(data) == 3:\n",
    "        if method == \"softmax\":\n",
    "\n",
    "            def hist_maker(hm_params):\n",
    "                \"\"\"Uses the nn decision function `predict` to form histograms\n",
    "                from signal and background data, all drawn from multivariate\n",
    "                normal distributions with different means. Two background\n",
    "                distributions are sampled from, which is meant to mimic the\n",
    "                situation in particle physics where one has a 'nominal'\n",
    "                prediction for a nuisance parameter (taken here as the mean of\n",
    "                two modes) and then alternate values (e.g. from varying up/down\n",
    "                by one standard deviation), which then modifies the background\n",
    "                pdf. Here, we take that effect to be a shift of the mean of the\n",
    "                distribution. The value for the background histogram is then\n",
    "                the mean of the resulting counts of the two modes, and the\n",
    "                uncertainty can be quantified through the count standard\n",
    "                deviation.\n",
    "\n",
    "                Arguments:\n",
    "                    hm_params: a list containing:\n",
    "                        nn: jax array of observable parameters.\n",
    "                \"\"\"\n",
    "                nn = hm_params\n",
    "                s, b_up, b_down = data\n",
    "                NMC = len(s)\n",
    "                s_hist = predict(nn, s).sum(axis=0) * sig_scale / NMC * LUMI\n",
    "\n",
    "                b_hists = [\n",
    "                    predict(nn, b_up).sum(axis=0)   * bkg_scale / NMC * LUMI,\n",
    "                    predict(nn, b_down).sum(axis=0) * bkg_scale / NMC * LUMI,\n",
    "                ]\n",
    "\n",
    "                b_mean = jnp.mean(jnp.asarray(b_hists), axis=0)\n",
    "                b_unc = jnp.std(jnp.asarray(b_hists), axis=0)\n",
    "\n",
    "                return s_hist, b_mean, b_unc\n",
    "\n",
    "        elif method == \"kde\":\n",
    "\n",
    "            def hist_maker(hm_params):\n",
    "                \"\"\"Uses the nn decision function `predict` to form histograms\n",
    "                from signal and background data using a kde, all drawn from\n",
    "                multivariate normal distributions with different means. Two\n",
    "                background distributions are sampled from, which is meant to\n",
    "                mimic the situation in particle physics where one has a\n",
    "                'nominal' prediction for a nuisance parameter (taken here as\n",
    "                the mean of two modes) and then alternate values (e.g. from\n",
    "                varying up/down by one standard deviation), which then modifies\n",
    "                the background pdf. Here, we take that effect to be a shift of\n",
    "                the mean of the distribution. The value for the background\n",
    "                histogram is then the mean of the resulting counts of the two\n",
    "                modes, and the uncertainty can be quantified through the count\n",
    "                standard deviation.\n",
    "\n",
    "                Arguments:\n",
    "                    hm_params: Array-like, consisting of:\n",
    "                        nn: jax array of observable parameters.\n",
    "\n",
    "                        bins: Array of bin edges, e.g. np.linspace(0,1,3) \n",
    "                              defines a two-bin histogram with edges at 0, 0.5, \n",
    "                              1.\n",
    "\n",
    "                        bandwidth: Float that controls the 'smoothness' of the \n",
    "                                   kde. It's recommended to keep this fairly \n",
    "                                   similar to the bin width to avoid \n",
    "                                   oversmoothing the distribution. Going too low\n",
    "                                   will cause things to break, as the gradients \n",
    "                                   of the kde become unstable.\n",
    "                \"\"\"\n",
    "                nn = hm_params\n",
    "                bins, bandwidth = hpar_dict[\"bins\"], hpar_dict[\"bandwidth\"]\n",
    "                s, b_up, b_down = data\n",
    "                NMC = len(s)\n",
    "\n",
    "                nn_s, nn_b_up, nn_b_down = (\n",
    "                    predict(nn, s).ravel(),\n",
    "                    predict(nn, b_up).ravel(),\n",
    "                    predict(nn, b_down).ravel(),\n",
    "                )\n",
    "\n",
    "                s_hist = hist(nn_s, bins, bandwidth) * sig_scale / NMC * LUMI\n",
    "\n",
    "                b_hists = jnp.asarray(\n",
    "                    [\n",
    "                        hist(nn_b_up, bins, bandwidth)   * bkg_scale / NMC * LUMI,\n",
    "                        hist(nn_b_down, bins, bandwidth) * bkg_scale / NMC * LUMI,\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                kde_counts = [\n",
    "                    s_hist,\n",
    "                    jnp.mean(b_hists, axis=0),\n",
    "                    jnp.std(b_hists, axis=0),\n",
    "                ]\n",
    "\n",
    "                return kde_counts\n",
    "\n",
    "        else:\n",
    "            assert False, (\n",
    "            f\"Unsupported method: {method}\"\n",
    "            \" (only using kde or softmax for these examples).\"\n",
    "            )\n",
    "                \n",
    "    elif len(data) == 4:\n",
    "        if method == \"softmax\":\n",
    "\n",
    "            def hist_maker(hm_params):\n",
    "                \"\"\"Uses the nn decision function `predict` to form histograms\n",
    "                from signal and background data, all drawn from multivariate\n",
    "                normal distributions with different means. Three background\n",
    "                distributions are sampled from, which mimics the situation in\n",
    "                particle physics where one has a 'nominal' prediction for a\n",
    "                nuisance parameter (taken here as the mean of two modes) and\n",
    "                then alternate values (e.g. from varying up/down by one\n",
    "                standard deviation), which then modifies the background pdf.\n",
    "                Here, we take that effect to be a shift of the mean of the\n",
    "                distribution. The HistFactory 'histosys' nusiance parameter\n",
    "                will then be constructed from the yields downstream by\n",
    "                interpolating between them using pyhf.\n",
    "\n",
    "                Arguments:\n",
    "                    hm_params: a list containing:\n",
    "                        nn: jax array of observable parameters.\n",
    "\n",
    "                Returns:\n",
    "                    Set of 4 counts for signal, background, and up/down modes.\n",
    "                \"\"\"\n",
    "                nn = hm_params\n",
    "                s, b_nom, b_up, b_down = data\n",
    "                NMC = len(s)\n",
    "                counts = [\n",
    "                    predict(nn, s).sum(axis=0)      * sig_scale / NMC * LUMI,\n",
    "                    predict(nn, b_nom).sum(axis=0)  * bkg_scale / NMC * LUMI,\n",
    "                    predict(nn, b_up).sum(axis=0)   * bkg_scale / NMC * LUMI,\n",
    "                    predict(nn, b_down).sum(axis=0) * bkg_scale / NMC * LUMI,\n",
    "                ]\n",
    "\n",
    "                return counts\n",
    "\n",
    "        elif method == \"kde\":\n",
    "\n",
    "            def hist_maker(hm_params):\n",
    "                \"\"\"Uses the nn decision function `predict` to form histograms\n",
    "                from signal and background data, all drawn from multivariate\n",
    "                normal distributions with different means. Three background\n",
    "                distributions are sampled from, which mimics the situation in\n",
    "                particle physics where one has a 'nominal' prediction for a\n",
    "                nuisance parameter (taken here as the mean of two modes) and\n",
    "                then alternate values (e.g. from varying up/down by one\n",
    "                standard deviation), which then modifies the background pdf.\n",
    "                Here, we take that effect to be a shift of the mean of the\n",
    "                distribution. The HistFactory 'histosys' nusiance parameter\n",
    "                will then be constructed from the yields downstream by\n",
    "                interpolating between them using pyhf.\n",
    "\n",
    "                Arguments:\n",
    "                    hm_params: Array-like, consisting of:\n",
    "                        nn: jax array of observable parameters.\n",
    "\n",
    "                        bins: Array of bin edges, e.g. np.linspace(0,1,3) \n",
    "                              defines a two-bin histogram with edges at 0, 0.5, \n",
    "                              1.\n",
    "\n",
    "                        bandwidth: Float that controls the 'smoothness' of the \n",
    "                                   kde. It's recommended to keep this fairly \n",
    "                                   similar to the bin width to avoid \n",
    "                                   oversmoothing the distribution. Going too low\n",
    "                                   will cause things to break, as the gradients \n",
    "                                   of the kde become unstable.\n",
    "\n",
    "                Returns:\n",
    "                    Set of 4 counts for signal, background, and up/down modes.\n",
    "                \"\"\"\n",
    "                nn = hm_params\n",
    "                bins, bandwidth = hpar_dict[\"bins\"], hpar_dict[\"bandwidth\"]\n",
    "                s, b_nom, b_up, b_down = data\n",
    "                NMC = len(s)\n",
    "\n",
    "                nn_s, nn_b_nom, nn_b_up, nn_b_down = (\n",
    "                    predict(nn, s).ravel(),\n",
    "                    predict(nn, b_nom).ravel(),\n",
    "                    predict(nn, b_up).ravel(),\n",
    "                    predict(nn, b_down).ravel(),\n",
    "                )\n",
    "\n",
    "                kde_counts = [\n",
    "                    hist(nn_s, bins, bandwidth)      * sig_scale / NMC * LUMI,\n",
    "                    hist(nn_b_nom, bins, bandwidth)  * bkg_scale / NMC * LUMI,\n",
    "                    hist(nn_b_up, bins, bandwidth)   * bkg_scale / NMC * LUMI,\n",
    "                    hist(nn_b_down, bins, bandwidth) * bkg_scale / NMC * LUMI,\n",
    "                ]\n",
    "\n",
    "                return kde_counts\n",
    "\n",
    "        else:\n",
    "            assert False, (\n",
    "            f\"Unsupported method: {method}\"\n",
    "            \" (only using kde or softmax for these examples).\"\n",
    "            )\n",
    "    else:\n",
    "        assert False, (\n",
    "            f\"Unsupported number of blobs: {blobs}\"\n",
    "            \" (only using 3 or 4 blobs for these examples).\"\n",
    "        )\n",
    "\n",
    "    return hist_maker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by instantiating `hists_from_nn` with a function that generates a 3 or 4-tuple of data (we have `generate_blobs` for this!), and a neural network `predict` method (takes inputs & weights, returns output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.random import PRNGKey\n",
    "from jax.experimental import stax\n",
    "\n",
    "import neos\n",
    "from neos.makers import hists_from_nn\n",
    "from neos.data import generate_blobs\n",
    "\n",
    "# data generator\n",
    "gen_data = generate_blobs(rng=PRNGKey(1),blobs=4)\n",
    "\n",
    "# nn\n",
    "init_random_params, predict = stax.serial(\n",
    "    stax.Dense(1024),\n",
    "    stax.Relu,\n",
    "    stax.Dense(1),\n",
    "    stax.Sigmoid\n",
    ")\n",
    "\n",
    "hist_maker = hists_from_nn(gen_data, predict, method='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when we initialize our neural network's weights and pass them to `hist_maker` along with some hyperparameters for the histogram (binning, bandwidth), we should get back a set of event yields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DeviceArray([6.76080181, 6.8832221 ], dtype=float64),\n",
       " DeviceArray([34.14177765, 34.12072566], dtype=float64),\n",
       " DeviceArray([35.10574108, 33.04116608], dtype=float64),\n",
       " DeviceArray([32.32513054, 35.63212448], dtype=float64)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, network = init_random_params(jax.random.PRNGKey(13), (-1, 2))\n",
    "\n",
    "hyperpars = dict(bandwidth=0.5, bins=jnp.linspace(0,1,3))\n",
    "\n",
    "hist_maker([network, hyperpars])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## statistical models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import pyhf\n",
    "\n",
    "jax_backend = pyhf.tensor.jax_backend(precision=\"64b\")\n",
    "pyhf.set_backend(jax_backend)\n",
    "\n",
    "from neos.models import hepdata_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def hepdata_like_from_hists(histogram_maker):\n",
    "    \"\"\"Returns a function that constructs a typical 'hepdata-like' statistical\n",
    "    model with signal, background, and background uncertainty yields when\n",
    "    evaluated at the parameters of the observable.\n",
    "\n",
    "    Args:\n",
    "        histogram_maker: A function that, when called, returns a secondary function\n",
    "        that takes the observable's parameters as argument, and returns yields.\n",
    "\n",
    "    Returns:\n",
    "        nn_model_maker: A function that returns a Model object (either from\n",
    "        `neos.models` or from `pyhf`) when evaluated at the observable's parameters,\n",
    "        along with the background-only parameters for use in downstream inference.\n",
    "    \"\"\"\n",
    "\n",
    "    def nn_model_maker(hm_params):\n",
    "        s, b, db = histogram_maker(hm_params)\n",
    "        m = hepdata_like(s, b, db)  # neos 'pyhf' model\n",
    "        nompars = m.config.suggested_init()\n",
    "        bonlypars = jnp.asarray([x for x in nompars])\n",
    "        bonlypars = jax.ops.index_update(bonlypars, m.config.poi_index, 0.0)\n",
    "        return m, bonlypars\n",
    "\n",
    "    return nn_model_maker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a hist_maker as above\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.random import PRNGKey\n",
    "from jax.experimental import stax\n",
    "\n",
    "import neos\n",
    "from neos.makers import hists_from_nn, hepdata_like_from_hists\n",
    "from neos.data import generate_blobs\n",
    "\n",
    "# data generator, three blobs only for this model\n",
    "gen_data = generate_blobs(rng=PRNGKey(1),blobs=3)\n",
    "\n",
    "# nn\n",
    "init_random_params, predict = stax.serial(\n",
    "    stax.Dense(1024),\n",
    "    stax.Relu,\n",
    "    stax.Dense(1),\n",
    "    stax.Sigmoid\n",
    ")\n",
    "\n",
    "hist_maker = hists_from_nn(gen_data, predict, method='kde')\n",
    "\n",
    "# then use this to define your model:\n",
    "model = hepdata_like_from_hists(hist_maker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to above, we can get output at this stage by initializing the neural network. `hepdata_like_from_hists` will return a `Model` object with callable `logpdf` method, as well as the model parameters in the background-only scenario for convenience. See [this link](https://scikit-hep.org/pyhf/_generated/pyhf.simplemodels.hepdata_like.html) for more about the type of model being used here, as well as the rest of the `pyhf` docs for added physics context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([-1338.66123891], dtype=float64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, network = init_random_params(jax.random.PRNGKey(13), (-1, 2))\n",
    "\n",
    "hyperpars = dict(bandwidth=0.5, bins=jnp.linspace(0,1,3))\n",
    "\n",
    "m, bkg_only_pars = model([network, hyperpars])\n",
    "m.logpdf(bkg_only_pars,data=[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import sys\n",
    "from unittest.mock import patch\n",
    "jax_backend = pyhf.tensor.jax_backend(precision='64b')\n",
    "pyhf.set_backend(jax_backend)\n",
    "\n",
    "def histosys_model_from_hists(histogram_maker):\n",
    "    \"\"\"Returns a function that constructs a HEP statistical model using a\n",
    "    'histosys' uncertainty for the background (nominal background, up and down\n",
    "    systematic variations) when evaluated at the parameters of the observable.\n",
    "\n",
    "    Args:\n",
    "        histogram_maker: A function that, when called, returns a secondary function\n",
    "        that takes the observable's parameters as argument, and returns yields.\n",
    "\n",
    "    Returns:\n",
    "        nn_model_maker: A function that returns a `pyhf.Model` object when \n",
    "        evaluated at the observable's parameters (nn weights), along with the \n",
    "        background-only parameters for use in downstream inference.\n",
    "    \"\"\"\n",
    "\n",
    "    @patch('pyhf.default_backend', new=jax_backend)\n",
    "    @patch.object(sys.modules['pyhf.interpolators.code0'], 'default_backend', new=jax_backend)\n",
    "    @patch.object(sys.modules['pyhf.interpolators.code1'], 'default_backend', new=jax_backend)\n",
    "    @patch.object(sys.modules['pyhf.interpolators.code2'], 'default_backend', new=jax_backend)\n",
    "    @patch.object(sys.modules['pyhf.interpolators.code4'], 'default_backend', new=jax_backend)\n",
    "    @patch.object(sys.modules['pyhf.interpolators.code4p'], 'default_backend', new=jax_backend)\n",
    "    @patch.object(sys.modules['pyhf.modifiers.shapefactor'], 'default_backend', new=jax_backend)\n",
    "    @patch.object(sys.modules['pyhf.modifiers.shapesys'], 'default_backend', new=jax_backend)\n",
    "    @patch.object(sys.modules['pyhf.modifiers.staterror'], 'default_backend', new=jax_backend)\n",
    "    def from_spec(yields):\n",
    "\n",
    "        s, b, bup, bdown = yields\n",
    "\n",
    "        spec = {\n",
    "            \"channels\": [\n",
    "                {\n",
    "                    \"name\": \"nn\",\n",
    "                    \"samples\": [\n",
    "                        {\n",
    "                            \"name\": \"signal\",\n",
    "                            \"data\": s,\n",
    "                            \"modifiers\": [\n",
    "                                {\"name\": \"mu\", \"type\": \"normfactor\", \"data\": None}\n",
    "                            ],\n",
    "                        },\n",
    "                        {\n",
    "                            \"name\": \"bkg\",\n",
    "                            \"data\": b,\n",
    "                            \"modifiers\": [\n",
    "                                {\n",
    "                                    \"name\": \"nn_histosys\",\n",
    "                                    \"type\": \"histosys\",\n",
    "                                    \"data\": {\n",
    "                                        \"lo_data\": bdown,\n",
    "                                        \"hi_data\": bup,\n",
    "                                    },\n",
    "                                }\n",
    "                            ],\n",
    "                        },\n",
    "                    ],\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "\n",
    "        return pyhf.Model(spec)\n",
    "\n",
    "    def nn_model_maker(hm_params):\n",
    "        yields = histogram_maker(hm_params)\n",
    "        m = from_spec(yields)\n",
    "        nompars = m.config.suggested_init()\n",
    "        bonlypars = jnp.asarray([x for x in nompars])\n",
    "        bonlypars = jax.ops.index_update(bonlypars, m.config.poi_index, 0.0)\n",
    "        return m, bonlypars\n",
    "\n",
    "    return nn_model_maker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([-62.62101506], dtype=float64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a hist_maker as above\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.random import PRNGKey\n",
    "from jax.experimental import stax\n",
    "\n",
    "import neos\n",
    "from neos.makers import hists_from_nn, histosys_model_from_hists\n",
    "from neos.data import generate_blobs\n",
    "\n",
    "# data generator, four blobs only for this model\n",
    "gen_data = generate_blobs(rng=PRNGKey(1),blobs=4)\n",
    "\n",
    "# nn\n",
    "init_random_params, predict = stax.serial(\n",
    "    stax.Dense(1024),\n",
    "    stax.Relu,\n",
    "    stax.Dense(1),\n",
    "    stax.Sigmoid\n",
    ")\n",
    "\n",
    "hist_maker = hists_from_nn(gen_data, predict, method='kde')\n",
    "\n",
    "# then use this to define your model:\n",
    "model = histosys_model_from_hists(hist_maker)\n",
    "\n",
    "_, network = init_random_params(jax.random.PRNGKey(13), (-1, 2))\n",
    "\n",
    "hyperpars = dict(bandwidth=0.5, bins=jnp.linspace(0,1,3))\n",
    "\n",
    "# instantiate model and eval logpdf\n",
    "m, bkg_only_pars = model([network, hyperpars])\n",
    "m.logpdf(bkg_only_pars,data=[1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('3.9.1': pyenv)",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
