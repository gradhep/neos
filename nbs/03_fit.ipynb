{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neos.fit\n",
    "\n",
    "> Module containing functions to perform maximum likelihod fits in a differentiable way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fax` module is leveraged to calculate gradients of maximum likelihood fits through the 'two-phase' method, which is a technique for automatic differentiation of functions with an attractive fixed point, i.e. they satisfy $f(x) - x = 0$. This is the case for a minimization routine, where the minimization occurs from the minimum: `minimize(f, x_init) = x_min` --> `minimize(f, x_init=x_min) = x_min`. You can imagine that the initial iterations won't give any useful information in terms of the gradient of the minimum; this approach leverages this fact by performing the minimization a second time in the neighborhood of the fixed point, and keeping track of gradients there, which avoids the unnecessary unrolling of many loops for the early iteration.\n",
    "\n",
    "To read more about this method, see section 2.3 of [this paper](https://www.researchgate.net/profile/Ala_Taftaf2/publication/323176030_ADJOINTS_OF_FIXED-POINT_ITERATIONS/links/5a8465644585159152b7fe00/ADJOINTS-OF-FIXED-POINT-ITERATIONS.pdf) that looks at some methods to approach the fixed-point differation problem within automatic differentiation.\n",
    "\n",
    "The fits themselves are done by gradient descent with Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import jax\n",
    "import jax.experimental.optimizers as optimizers\n",
    "from fax.implicit import twophase\n",
    "\n",
    "from neos.models import *\n",
    "from neos.transforms import to_bounded, to_bounded_vec, to_inf, to_inf_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_solvers(\n",
    "    model_constructor,\n",
    "    pdf_transform=False,\n",
    "    default_rtol=1e-10,\n",
    "    default_atol=1e-10,\n",
    "    default_max_iter=int(1e7),\n",
    "    learning_rate=0.01,\n",
    "):\n",
    "    \"\"\"\n",
    "    Wraps a series of functions that perform maximum likelihood fitting in the \n",
    "    `two_phase_solver` method found in the `fax` python module. This allows for\n",
    "    the calculation of gradients of the best-fit parameters with respect to upstream\n",
    "    parameters that control the underlying model, i.e. the event yields (which are \n",
    "    then parameterized by weights or similar).\n",
    "    \n",
    "    Args:\n",
    "            model_constructor: Function that takes in the parameters of the observable,\n",
    "            and returns a model object (and background-only parameters)\n",
    "    Returns:\n",
    "            g_fitter, c_fitter: Callable functions that perform global and constrained fits\n",
    "            respectively. Differentiable :)\n",
    "    \"\"\"\n",
    "\n",
    "    adam_init, adam_update, adam_get_params = optimizers.adam(1e-6)\n",
    "\n",
    "    def make_model(hyper_pars):\n",
    "        constrained_mu, nn_pars = hyper_pars[0], hyper_pars[1]\n",
    "        m, bonlypars = model_constructor(nn_pars)\n",
    "\n",
    "        bounds = m.config.suggested_bounds()\n",
    "        constrained_mu = (\n",
    "            to_inf(constrained_mu, bounds[0]) if pdf_transform else constrained_mu\n",
    "        )\n",
    "\n",
    "        exp_bonly_data = m.expected_data(bonlypars, include_auxdata=True)\n",
    "\n",
    "        def expected_logpdf(pars):  # maps pars to bounded space if pdf_transform = True\n",
    "\n",
    "            return (\n",
    "                m.logpdf(to_bounded_vec(pars, bounds), exp_bonly_data)\n",
    "                if pdf_transform\n",
    "                else m.logpdf(pars, exp_bonly_data)\n",
    "            )\n",
    "\n",
    "        def global_fit_objective(pars):  # NLL\n",
    "            return -expected_logpdf(pars)[0]\n",
    "\n",
    "        def constrained_fit_objective(nuis_par):  # NLL\n",
    "            pars = jax.numpy.concatenate(\n",
    "                [jax.numpy.asarray([constrained_mu]), nuis_par]\n",
    "            )\n",
    "            return -expected_logpdf(pars)[0]\n",
    "\n",
    "        return constrained_mu, global_fit_objective, constrained_fit_objective, bounds\n",
    "\n",
    "    def global_bestfit_minimized(hyper_param):\n",
    "        _, nll, _, _ = make_model(hyper_param)\n",
    "\n",
    "        def bestfit_via_grad_descent(i, param):  # gradient descent\n",
    "            g = jax.grad(nll)(param)\n",
    "            # param = param - g * learning_rate\n",
    "            param = adam_get_params(adam_update(i, g, adam_init(param)))\n",
    "            return param\n",
    "\n",
    "        return bestfit_via_grad_descent\n",
    "\n",
    "    def constrained_bestfit_minimized(hyper_param):\n",
    "        mu, nll, cnll, bounds = make_model(hyper_param)\n",
    "\n",
    "        def bestfit_via_grad_descent(i, param):  # gradient descent\n",
    "            _, np = param[0], param[1:]\n",
    "            g = jax.grad(cnll)(np)\n",
    "            np = adam_get_params(adam_update(i, g, adam_init(np)))\n",
    "            param = jax.numpy.concatenate([jax.numpy.asarray([mu]), np])\n",
    "            return param\n",
    "\n",
    "        return bestfit_via_grad_descent\n",
    "\n",
    "    global_solve = twophase.two_phase_solver(\n",
    "        param_func=global_bestfit_minimized,\n",
    "        default_rtol=default_rtol,\n",
    "        default_atol=default_atol,\n",
    "        default_max_iter=default_max_iter,\n",
    "    )\n",
    "    constrained_solver = twophase.two_phase_solver(\n",
    "        param_func=constrained_bestfit_minimized,\n",
    "        default_rtol=default_rtol,\n",
    "        default_atol=default_atol,\n",
    "        default_max_iter=default_max_iter,\n",
    "    )\n",
    "\n",
    "    def g_fitter(init, hyper_pars):\n",
    "        solve = global_solve(init, hyper_pars)\n",
    "        return solve.value\n",
    "\n",
    "    def c_fitter(init, hyper_pars):\n",
    "        solve = constrained_solver(init, hyper_pars)\n",
    "        return solve.value\n",
    "\n",
    "    return g_fitter, c_fitter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
